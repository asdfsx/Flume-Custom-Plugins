# example.conf: A single-node Flume configuration
# Name the components on this agent
a1.sources = n1 n2
a1.sinkgroups = g1
a1.sinks = kk k1 k2 k3 k4 k5 k6 k7 k8 k9 k10 k11 k12 k13 k14 k15 k16 k17 k18 k19 k20
a1.channels = c1 c2

# Describe/configure the source
a1.sources.n1.type = com.engine.flume.source.HTTPSource
a1.sources.n1.bind = 0.0.0.0
a1.sources.n1.port = 15140
a1.sources.n1.poolsize = 256
a1.sources.n1.handler = com.engine.flume.source.AllParamHandler

a1.sources.n2.type = avro
a1.sources.n2.channels = c1
a1.sources.n2.bind = localhost
a1.sources.n2.port = 15141

# Describe the sink group
a1.sinkgroups.g1.sinks = k1 k2 k3 k4 k5 k6 k7 k8 k9 k10 k11 k12 k13 k14 k15 k16 k17 k18 k19 k20
a1.sinkgroups.g1.processor.type = load_balance
a1.sinkgroups.g1.processor.backoff = true
a1.sinkgroups.g1.processor.selector = round_robin

# Describe the sink
#a1.sinks.k1.type = logger
a1.sinks.kk.type = avro
a1.sinks.kk.batch-size = 1000
a1.sinks.kk.channel = c1
a1.sinks.kk.hostname = localhost
a1.sinks.kk.port = 15141

a1.sinks.k1.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k1.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k1.topic = sztest12345 
a1.sinks.k1.batchsize = 100
a1.sinks.k1.producer.type = async
a1.sinks.k1.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k2.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k2.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k2.topic = sztest12345
a1.sinks.k2.batchsize = 100
a1.sinks.k2.producer.type = async
a1.sinks.k2.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k3.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k3.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k3.topic = sztest12345
a1.sinks.k3.batchsize = 100
a1.sinks.k3.producer.type = async
a1.sinks.k3.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k4.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k4.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k4.topic = sztest12345
a1.sinks.k4.batchsize = 100
a1.sinks.k4.producer.type = async
a1.sinks.k4.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k5.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k5.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k5.topic = sztest12345
a1.sinks.k5.batchsize = 100
a1.sinks.k5.producer.type = async
a1.sinks.k5.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k6.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k6.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k6.topic = sztest12345
a1.sinks.k6.batchsize = 100
a1.sinks.k6.producer.type = async
a1.sinks.k6.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k7.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k7.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k7.topic = sztest12345
a1.sinks.k7.batchsize = 100
a1.sinks.k7.producer.type = async
a1.sinks.k7.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k8.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k8.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k8.topic = sztest12345
a1.sinks.k8.batchsize = 100
a1.sinks.k8.producer.type = async
a1.sinks.k8.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k8.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k8.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k8.topic = sztest12345
a1.sinks.k8.batchsize = 100
a1.sinks.k8.producer.type = async
a1.sinks.k8.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k9.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k9.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k9.topic = sztest12345
a1.sinks.k9.batchsize = 100
a1.sinks.k9.producer.type = async
a1.sinks.k9.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k10.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k10.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k10.topic = sztest12345
a1.sinks.k10.batchsize = 100
a1.sinks.k10.producer.type = async
a1.sinks.k10.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k11.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k11.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k11.topic = sztest12345
a1.sinks.k11.batchsize = 100
a1.sinks.k11.producer.type = async
a1.sinks.k11.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k12.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k12.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k12.topic = sztest12345
a1.sinks.k12.batchsize = 100
a1.sinks.k12.producer.type = async
a1.sinks.k12.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k13.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k13.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k13.topic = sztest12345
a1.sinks.k13.batchsize = 100
a1.sinks.k13.producer.type = async
a1.sinks.k13.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k14.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k14.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k14.topic = sztest12345
a1.sinks.k14.batchsize = 100
a1.sinks.k14.producer.type = async
a1.sinks.k14.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k15.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k15.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k15.topic = sztest12345
a1.sinks.k15.batchsize = 100
a1.sinks.k15.producer.type = async
a1.sinks.k15.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k16.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k16.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k16.topic = sztest12345
a1.sinks.k16.batchsize = 100
a1.sinks.k16.producer.type = async
a1.sinks.k16.serializer.class = kafka.serializer.StringEncoder


a1.sinks.k17.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k17.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k17.topic = sztest12345
a1.sinks.k17.batchsize = 100
a1.sinks.k17.producer.type = async
a1.sinks.k17.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k18.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k18.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k18.topic = sztest12345
a1.sinks.k18.batchsize = 100
a1.sinks.k18.producer.type = async
a1.sinks.k18.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k19.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k19.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k19.topic = sztest12345
a1.sinks.k19.batchsize = 100
a1.sinks.k19.producer.type = async
a1.sinks.k19.serializer.class = kafka.serializer.StringEncoder

a1.sinks.k20.type = com.engine.kafka.sink.KafkaSink
a1.sinks.k20.metadata.broker.list = 192.168.18.72:9092
a1.sinks.k20.topic = sztest12345
a1.sinks.k20.batchsize = 100
a1.sinks.k20.producer.type = async
a1.sinks.k20.serializer.class = kafka.serializer.StringEncoder

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 100000
a1.channels.c1.transactionCapacity = 1000

# Use a channel which buffers events in file
a1.channels.c2.type = file
a1.channels.c2.checkpointDir = /data/flume/checkpoint
a1.channels.c2.dataDirs = /data/flume/data
a1.channels.c2.transactionCapacity = 1000
a1.channels.c2.capacity = 1000000

# Bind the source and sink to the channel
a1.sources.n1.channels = c1
a1.sinks.kk.channels = c1


a1.sources.n2.channels = c2
a1.sinks.k1.channel = c2
a1.sinks.k2.channel = c2
a1.sinks.k3.channel = c2
a1.sinks.k4.channel = c2
a1.sinks.k5.channel = c2
a1.sinks.k6.channel = c2
a1.sinks.k7.channel = c2
a1.sinks.k8.channel = c2
a1.sinks.k9.channel = c2
a1.sinks.k10.channel = c2
a1.sinks.k11.channel = c2
a1.sinks.k12.channel = c2
a1.sinks.k13.channel = c2
a1.sinks.k14.channel = c2
a1.sinks.k15.channel = c2
a1.sinks.k16.channel = c2
a1.sinks.k17.channel = c2
a1.sinks.k18.channel = c2
a1.sinks.k19.channel = c2
a1.sinks.k20.channel = c2